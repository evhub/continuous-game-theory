from tqdm import tqdm

from iternash.util import Str, clean_env
from iternash.agent import Agent, init_agent


class Game:
    """Game class.

    Parameters:
    - _name_ is the name of the game.
    - _agents_ are agents to include in the environment. (name, agent) tuples
        are also allowed.
    - _named_agents_ are names mapped to agents to give those names to in the
        env. _named_agents_ come after _agents_ in an arbitrary order.
    - _independent_update_ controls whether agents are evaluated independently
        or sequentially (defaults to False, i.e. sequentially). When the updates
        are sequential the order of agents passed to Game will be the order in
        which they are evaluated at each step.
    - _default_run_kwargs_ are keyword arguments to use as the defaults in run.
    """
    final_step = False

    match def __init__(self, name is Str, *agents, independent_update=False, default_run_kwargs={}, **named_agents):
        self.name = None
        self.agents = []
        self.independent_update = independent_update
        self.default_run_kwargs = default_run_kwargs
        self.reset(name, *agents, **named_agents)

    def reset(self, name, *agents, **named_agents):
        """Set all default values and start the step counter. If you want to call run
        multiple times on the same game you must explicitly call reset and if you are
        using bbopt agents you must pass a new _name_."""
        self.name = name ?? self.name
        self.add_agents(*agents, **named_agents)
        self.env = {"game": self}
        for a in self.agents:
            if a.has_default() and a.name is not None:
                self.env[a.name] = a.default
        self.i = 0
        return self

    def add_agents(self, *agents, **named_agents):
        """Add the given agents/variables to the game."""
        for a in agents :: named_agents.items():
            match (name, actor) in a:
                if not callable(actor):
                    a = init_agent(name, actor)
                elif isinstance(actor, Agent):
                    a = actor.clone(name=name)
                else:
                    a = Agent(name, actor)
            assert isinstance(a, Agent), f"not isinstance({a}, Agent)"
            self.agents.append(a)
        return self

    def attach(self, agent, period, name=None):
        """Add an agent to be called at interval _period_."""
        if isinstance(agent, Agent):
            agent = agent.clone(name=name, period=period)
        else:
            agent = Agent(name, agent, period=period)
        self.agents.append(agent)
        return self

    def step(self):
        """Perform one full step of action selection."""
        updating_env = {} if self.independent_update else self.env
        for a in self.agents:
            if self.i % a.period == 0:
                action = a(self.env)
                if a.name is not None:
                    updating_env[a.name] = action
        if self.independent_update:
            self.env.update(updating_env)
        self.i += 1

    def env_copy(self):
        """Get a copy of the environment without the game."""
        new_env = clean_env(self.env)
        for a in self.agents:
            if a.copy_func is not None:
                new_env[a.name] = a.copy_func(new_env[a.name])
        return new_env

    @property
    def max_period(self) =
        max(a.period for a in self.agents if a.period < float("inf"))

    def run(self, max_steps=None, **kwargs):
        """Exactly base_run but includes default_run_kwargs."""
        run_kwargs = self.default_run_kwargs.copy()
        if max_steps is not None:
            run_kwargs["max_steps"] = max_steps
        run_kwargs.update(kwargs)
        return self.base_run(**run_kwargs)

    def base_run(self, max_steps=None, stop_at_equilibrium=False, ensure_all_agents_run=True):
        """Run iterative action selection for _max_steps_ or
        until equilibrium is reached if _stop_at_equilibrium_."""
        if max_steps is None and not stop_at_equilibrium:
            raise ValueError("run needs either max_steps not None or stop_at_equilibrium True")
        if stop_at_equilibrium:
            prev_env = self.env_copy()
        for _ in tqdm(range(max_steps)) if max_steps is not None else count():
            self.step()
            if stop_at_equilibrium and self.i % self.max_period == 0:
                new_env = self.env_copy()
                if new_env == prev_env:
                    break
                prev_env = new_env
        return self.finalize(ensure_all_agents_run=ensure_all_agents_run)

    def finalize(self, ensure_all_agents_run=True):
        """Gather final parameters, running every agent again if _ensure_all_agents_run_."""
        self.final_step = True
        try:
            if ensure_all_agents_run:
                for _ in range(self.max_period):
                    self.step()
            return self.env_copy()
        finally:
            self.final_step = False
