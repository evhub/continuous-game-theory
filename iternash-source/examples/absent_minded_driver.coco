from scipy.special import comb
from mpmath import hyp2f1

from iternash import (
    Game,
    agent,
    expr_agent,
    bbopt_agent,
    debug_agent,
)


common_params = dict(
    # number of deployment episodes
    m=100,
    # desired PC for the n agent to attempt to achieve
    eps=0.01,
    # probability of training defection leading to no reward for that agent
    p_mod=0.9,
    # utility for defecting during training
    r_n=0,
    # utility for defecting during deployment
    r_m=1,
    # utility for never defecting
    r_f=0,
)


# conservative estimate of required training episodes
conservative_n_agent = expr_agent(
    name="n",
    expr="m/p_mod * (1-eps)/eps",
    default=common_params["m"],
)


# black-box-optimized n agent that attempts to set PC to eps
bbopt_n_agent = bbopt_agent(
    name="n",
    tunable_actor=(bb, env) ->
        int(conservative_n_agent(env) * bb.loguniform("n/n_c", 0.001, 1000)),
    util_func=expr_agent(None, "-abs(math.log(PC) - math.log(eps))"),
    file=__file__,
    default=common_params["m"],
)


# optimal defection probability in the sequential defection game
#  (note that this formula is recursive and requires iteration to solve)
seq_d_p_agent = expr_agent(
    name="p",
    # TODO: Verify/improve this formula.
    expr="""(
    (n * p_mod - (d-1)/(1-p))
    / (n * p_mod + m - (d-1)/(1-p))
    * (r_m - r_n)/(r_m - r_f)
)^(1/(m-d))""",
    default=0.9,
)


# probability of catastrophe in the sequential defection game
seq_d_PC_agent = expr_agent(
    name="PC",
    expr="(1-p)^(d-1) * (1 - p^(m-d+1))",
    default=0.1,
)


# optimal defection probability in the non-sequential two defection game
nonseq_2d_p_agent = expr_agent(
    name="p",
    expr="""(
    (n * p_mod)
    / (n * p_mod + m*(m-1))
    * (r_m - r_n)/(r_m - r_f)
)^(1/(m-1))""",
    default=0.9,
)


# probability of catastrophe in the non-sequential two defection game
nonseq_2d_PC_agent = expr_agent(
    name="PC",
    expr="1 - p^m - m*(1-p)*p^(m-1)",
    default=0.1,
)


# black-box-optimized p agent that attempts to find the optimal p
#  in the non-sequential defection game
nonseq_d_bbopt_p_agent = bbopt_agent(
    name="p",
    tunable_actor=(bb, env) -> 1 - bb.loguniform("p", 0.000001, 1),
    util_func=(def env ->
        p = env["p"];
        p_mod = env["p_mod"];
        n = env["n"];
        PC = env["PC"];
        (p + (1-p)*(1-p_mod))**n * PC
    ),
    file=__file__,
    default=0.9,
)


# probability of catastrophe in the non-sequential defection game
@agent(name="PC", default=0.1)
def nonseq_d_PC_agent(env) =
    comb(m, d) * p**(m-d) * (1-p)**d * (float..hyp2f1)(1, d-m, d+1, (p-1)/p) where:
        m = env["m"]
        d = env["d"]
        p = env["p"]


# agent that prints n, p, PC every 100 steps
printing_debugger = debug_agent("n = {n}; p = {p}; PC = {PC}", period=100)


# absent-minded driver game where catastrophe occurs if there are
#  ever d sequential defections during deployment
seq_d_game = Game(
    "seq_d_game",
    conservative_n_agent,
    seq_d_PC_agent,
    seq_d_p_agent,
    printing_debugger,
    # necessary number of sequential defections
    d=2,
    **common_params,
)


# absent-minded driver game where catastrophe occurs upon the
#  second defection during deployment
nonseq_2d_game = Game(
    "nonseq_2d_game",
    bbopt_n_agent,
    nonseq_2d_p_agent,
    nonseq_2d_PC_agent,
    printing_debugger,
    **common_params,
)


# absent-minded driver game where catastrophe occurs upon the
#  dth defection during deployment
nonseq_d_game = Game(
    "nonseq_d_game",
    nonseq_d_bbopt_p_agent,
    bbopt_n_agent,
    nonseq_d_PC_agent,
    printing_debugger,
    # necessary number of non-sequential defections
    d=2,
    **common_params,
)


if __name__ == "__main__":
    print("Running sequential defection game...")
    seq_d_game.run(500) |> print

    print("Running non-sequential two defection game...")
    nonseq_2d_game.run(500) |> print

    print("Running non-sequential defection game...")
    nonseq_d_game.run(500) |> print
