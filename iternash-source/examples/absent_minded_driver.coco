from scipy.special import comb
from mpmath import hyp2f1

from iternash import (
    Game,
    agent,
    expr_agent,
    bbopt_agent,
    debug_agent,
)


common_params = dict(
    # number of deployment episodes
    m=100,
    # desired PC for the n agent to attempt to achieve
    eps=0.01,
    # probability of training defection leading to no reward for that agent
    p_mod=0.9,
    # utility for defecting during training
    r_n=0,
    # utility for defecting during deployment
    r_m=1,
    # utility for never defecting
    r_f=0,
)


# optimal training episodes in the one defection game
baseline_n_agent = expr_agent(
    name="n",
    expr="m/p_mod * (1-eps)/eps",
    default=common_params["m"],
)


# optimal defection probability in the one defection game
baseline_p_agent = expr_agent(
    name="p",
    expr="""(
        (n * p_mod)
        / (n * p_mod + m)
        * (r_m - r_n)/(r_m - r_f)
    )**(1/(m-1))""",
    default=0.9,
)


# probability of catastrophe in the sequential defection game
seq_d_PC_agent = expr_agent(
    name="PC",
    expr="(1-p)**(d-1) * (1 - p**(m-d+1))",
    default=0.1,
)


# generic expected reward calculator
ER_agent = expr_agent(
    name="ER",
    expr="r_n * (1 - (p + (1-p)*(1-p_mod))**n) + (p + (1-p)*(1-p_mod))**n * (r_m * PC + r_f * (1 - PC))",
)


# optimal defection probability in the sequential defection game
#  (note that this formula is recursive and requires iteration to solve)
@agent(name="p", default=0.9)
def seq_d_p_agent(env):
    inner_p = env |> expr_agent(
        name="inner_p",
        # TODO: Check that the (r_m - r_n)/(r_m - r_f) factor is correct here.
        expr="""
        (n * p_mod - (d-1)/(1-p))
        / (n * p_mod + m - (d-1)/(1-p))
        * (r_m - r_n)/(r_m - r_f)
        """,
    )
    if 0 < inner_p < 1:
        m = env["m"]
        d = env["d"]
        return inner_p**(1/(m-d))
    else:
        return 0.1


# black-box-optimized n agent that attempts to set PC to eps
bbopt_n_agent = bbopt_agent(
    name="n",
    tunable_actor=(bb, env) ->
        int(baseline_n_agent(env) * bb.loguniform("n/n_c", 0.001, 1000)),
    util_func=expr_agent(None, "-abs(math.log(PC) - math.log(eps))"),
    file=__file__,
    default=common_params["m"],
)


# probability of catastrophe in the non-sequential two defection game
nonseq_2d_PC_agent = expr_agent(
    name="PC",
    expr="1 - p**m - m*(1-p)*p**(m-1)",
    default=0.1,
)


# optimal defection probability in the non-sequential two defection game
nonseq_2d_p_agent = expr_agent(
    name="p",
    # TODO: Check that the (r_m - r_n)/(r_m - r_f) factor is correct here.
    expr="""(
        (n * p_mod)
        / (n * p_mod + m*(m-1))
        * (r_m - r_n)/(r_m - r_f)
    )**(1/(m-1))""",
    default=0.9,
)


# probability of catastrophe in the non-sequential defection game
@agent(name="PC", default=0.1)
def nonseq_d_PC_agent(env) =
    comb(m, d) * p**(m-d) * (1-p)**d * (float..hyp2f1)(1, d-m, d+1, (p-1)/p) where:
        m = env["m"]
        d = env["d"]
        p = env["p"]


# black-box-optimized p agent that attempts to find the optimal p
#  in the non-sequential defection game
nonseq_d_bbopt_p_agent = bbopt_agent(
    name="p",
    tunable_actor=(bb, env) -> 1 - bb.loguniform("p", 0.000001, 1),
    util_func=.["ER"],
    file=__file__,
    default=0.9,
)


# agent that prints n, p, PC every 100 steps
printing_debugger = debug_agent("n = {n}; p = {p}; PC = {PC}", period=100)


# absent-minded driver game where catastrophe occurs on the first defection
baseline_game = Game(
    "baseline",
    baseline_n_agent,
    baseline_p_agent,
    seq_d_PC_agent,
    ER_agent,
    d=1,
    **common_params,
)


# absent-minded driver game where catastrophe occurs if there are ever
#  d sequential defections during deployment with a conservative n
conservative_seq_d_game = Game(
    "seq_d",
    baseline_n_agent,
    seq_d_p_agent,
    seq_d_PC_agent,
    ER_agent,
    printing_debugger.clone(period=200),
    # necessary number of sequential defections
    d=2,
    **common_params,
)


# absent-minded driver game where catastrophe occurs if there are ever
#  d sequential defections during deployment approximated by BBopt agents
approx_seq_d_game = Game(
    "seq_d",
    bbopt_n_agent.clone(period=10),
    seq_d_p_agent,
    seq_d_PC_agent,
    ER_agent,
    printing_debugger.clone(period=500),
    # necessary number of sequential defections
    d=2,
    **common_params,
)


# absent-minded driver game where catastrophe occurs upon the
#  second defection during deployment with a conservative n
conservative_nonseq_2d_game = Game(
    "nonseq_2d",
    baseline_n_agent,
    nonseq_2d_p_agent,
    nonseq_2d_PC_agent,
    ER_agent,
    printing_debugger,
    **common_params,
)


# absent-minded driver game where catastrophe occurs upon the
#  second defection during deployment
nonseq_2d_game = Game(
    "nonseq_2d",
    bbopt_n_agent,
    nonseq_2d_p_agent,
    nonseq_2d_PC_agent,
    ER_agent,
    printing_debugger,
    **common_params,
)


# absent-minded driver game where catastrophe occurs upon the
#  dth defection during deployment approximated by BBopt agents
approx_nonseq_d_game = Game(
    "nonseq_d",
    nonseq_d_PC_agent,
    ER_agent,
    nonseq_d_bbopt_p_agent,
    bbopt_n_agent,
    printing_debugger,
    independent_update=True,
    # necessary number of non-sequential defections
    d=2,
    **common_params,
)


if __name__ == "__main__":
    print("\nRunning baseline game...")
    baseline_game.run(1) |> print

    print(f"\nRunning conservative sequential defection game with d = {conservative_seq_d_game.env['d']}...")
    conservative_seq_d_game.run(1000) |> print

    print(f"\nRunning approximate sequential defection game with d = {approx_seq_d_game.env['d']}...")
    approx_seq_d_game.run(5000) |> print

    print("\nRunning conservative non-sequential two defection game...")
    conservative_nonseq_2d_game.run(500) |> print

    print("\nRunning non-sequential two defection game...")
    nonseq_2d_game.run(500) |> print

    print(f"\nRunning approximate non-sequential defection game with d = {approx_nonseq_d_game.env['d']}...")
    approx_nonseq_d_game.run(500) |> print
